{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client, config\n",
    "from kubernetes.client.rest import ApiException\n",
    "import time\n",
    "\n",
    "\n",
    "from kubernetes import client, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to create a deployment for a pod\n",
    "def create_deployment(api_instance, name, namespace, container_image, container_port):\n",
    "    # Configureate Pod template container\n",
    "    container = client.V1Container(\n",
    "        name=name,\n",
    "        image=container_image,\n",
    "        ports=[client.V1ContainerPort(container_port=container_port)])\n",
    "    # Create and configurate a spec section\n",
    "    template = client.V1PodTemplateSpec(\n",
    "        metadata=client.V1ObjectMeta(labels={\"app\": name}),\n",
    "        spec=client.V1PodSpec(containers=[container]))\n",
    "    # Create the specification of deployment\n",
    "    spec = client.V1DeploymentSpec(\n",
    "        replicas=1,\n",
    "        template=template,\n",
    "        selector={'matchLabels': {'app': name}})\n",
    "    # Instantiate the deployment object\n",
    "    deployment = client.V1Deployment(\n",
    "        api_version=\"apps/v1\",\n",
    "        kind=\"Deployment\",\n",
    "        metadata=client.V1ObjectMeta(name=name),\n",
    "        spec=spec)\n",
    "    # Create a deployment\n",
    "    api_response = api_instance.create_namespaced_deployment(\n",
    "        body=deployment,\n",
    "        namespace=namespace)\n",
    "    print(\"Deployment created. status='%s'\" % str(api_response.status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using prometheus to sum all the network_receive_bytes_total for a node in a given time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment created. status='{'available_replicas': None,\n",
      " 'collision_count': None,\n",
      " 'conditions': None,\n",
      " 'observed_generation': None,\n",
      " 'ready_replicas': None,\n",
      " 'replicas': None,\n",
      " 'unavailable_replicas': None,\n",
      " 'updated_replicas': None}'\n"
     ]
    }
   ],
   "source": [
    "#using the above funtion to create a nginx pod in default namespace\n",
    "def main():\n",
    "    config.load_kube_config()\n",
    "    apps_v1 = client.AppsV1Api()\n",
    "    create_deployment(apps_v1, \"nginx\", \"default\", \"nginx:1.7.9\", 80)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pod_node(pod_name):\n",
    "    # Load the kube config and Create a CoreV1Api instance\n",
    "    config.load_kube_config()\n",
    "    v1 = client.CoreV1Api()\n",
    "\n",
    "    try:\n",
    "        # Fetch the pods across all namespaces\n",
    "        pods = v1.list_pod_for_all_namespaces().items\n",
    "\n",
    "        # Filter the list for the specified pod name\n",
    "        matching_pods = [pod for pod in pods if pod.metadata.name == pod_name]\n",
    "\n",
    "        # Handle cases where no matches or multiple matches are found\n",
    "        if not matching_pods:\n",
    "            print(f\"No pod found with name {pod_name}\")\n",
    "            return None\n",
    "        elif len(matching_pods) > 1: # multiple pods with the same name in different namespaces\n",
    "            print(f\"Multiple pods found with the name {pod_name}. Specify a namespace.\")\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"Pod {pod_name} is running at node: {matching_pods[0].spec.node_name}\")\n",
    "            return matching_pods[0].spec.node_name\n",
    "\n",
    "    except client.exceptions.ApiException as e:\n",
    "        print(f\"An error occurred: {e.reason}. {e.body}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def change_node_for_pod(pod_name, pod_nameapce, new_assigned_node_name):\n",
    "    # Beofre scheduling the pod:\n",
    "    print(\"********************Before scheduling the pod ********************\")\n",
    "    \n",
    "    # get node name\n",
    "    old_assigned_node_name = get_pod_node(pod_name)\n",
    "    # Load the kube config\n",
    "    config.load_kube_config()\n",
    "    # Create API instances\n",
    "    core_v1 = client.CoreV1Api()\n",
    "\n",
    "    try:\n",
    "        # Step 1: Cordon all nodes except the new node\n",
    "        # Get the list of nodes\n",
    "        nodes = core_v1.list_node().items\n",
    "        # Loop through the nodes\n",
    "        for node in nodes:\n",
    "            # Skip the new node\n",
    "            if node.metadata.name == new_assigned_node_name:\n",
    "                continue\n",
    "            # Cordon the node\n",
    "            body = client.V1Node(spec=client.V1NodeSpec(unschedulable=True))\n",
    "            core_v1.patch_node(name=node.metadata.name, body=body)\n",
    "            #print all cordoned nodes\n",
    "            # print(f\"Node {node.metadata.name} has been cordoned\")\n",
    "            \n",
    "\n",
    "        # Get the existing pod details & specify the namespace (different namespace may have pods with same name)\n",
    "        pod = core_v1.read_namespaced_pod(name=pod_name, namespace=pod_nameapce)\n",
    "        \n",
    "        # Check if the pod is on the old node\n",
    "        if pod.spec.node_name != old_assigned_node_name:\n",
    "            print(f\"The pod is not on the node {old_assigned_node_name}\")\n",
    "            return\n",
    "        # Set the node name in the pod spec to the new node\n",
    "        pod.spec.node_name = new_assigned_node_name\n",
    "\n",
    "        # Remove fields that should not be set when creating a new object\n",
    "        pod.metadata.resource_version = None\n",
    "        pod.metadata.uid = None\n",
    "        pod.metadata.self_link = None\n",
    "        pod.metadata.creation_timestamp = None\n",
    "        pod.status = None\n",
    "\n",
    "        # Delete the old pod\n",
    "        core_v1.delete_namespaced_pod(name=pod_name, namespace=pod_nameapce)\n",
    "\n",
    "        # Wait for the pod to be fully deleted\n",
    "        while True:\n",
    "            try:\n",
    "                core_v1.read_namespaced_pod(name=pod_name, namespace=pod_nameapce)\n",
    "                time.sleep(0) # change from 1 to 0\n",
    "            except ApiException as e:\n",
    "                if e.status == 404:\n",
    "                    break\n",
    "\n",
    "        # Step 2: Create a new pod on the new node\n",
    "        core_v1.create_namespaced_pod(namespace=pod_nameapce, body=pod)\n",
    "        print(f\"Pod {pod_name} has been moved to node {new_assigned_node_name}\")\n",
    "\n",
    "    except ApiException as e:\n",
    "        print(f\"An error occurred: {e.reason}. {e.body}\")\n",
    "        return\n",
    "\n",
    "    # After scheduling the pod:\n",
    "    print(\"********************After scheduling the pod ********************\")\n",
    "\n",
    "    # Step 3: Uncordon the all cordoned nodes\n",
    "    # Get the list of nodes\n",
    "    nodes = core_v1.list_node().items\n",
    "    # Loop through the nodes\n",
    "    for node in nodes:\n",
    "        # Skip the new node\n",
    "        if node.metadata.name == new_assigned_node_name:\n",
    "            continue\n",
    "        # Uncordon the all cordoned nodes\n",
    "        body = client.V1Node(spec=client.V1NodeSpec(unschedulable=False))\n",
    "        core_v1.patch_node(name=node.metadata.name, body=body)\n",
    "        #print all cordoned nodes\n",
    "        # print(f\"Node {node.metadata.name} has been uncordoned\")\n",
    "    \n",
    "    \n",
    "    # get the new name for the pod and print it\n",
    "    new_pod_name = pod.metadata.name\n",
    "    print(f\"New pod name is: {new_pod_name}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Before scheduling the pod ********************\n",
      "Pod nginx-thrift-86c98b895b-rpnhr is running at node: k8s-worker-3\n",
      "Pod nginx-thrift-86c98b895b-rpnhr has been moved to node k8s-worker-7\n",
      "********************After scheduling the pod ********************\n",
      "New pod name is: nginx-thrift-86c98b895b-rpnhr\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "# change pod to another node        \n",
    "change_node_for_pod(pod_name=\"nginx-thrift-86c98b895b-rpnhr\", pod_nameapce=\"social-network\" , new_assigned_node_name=\"k8s-worker-7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Before scheduling the pod ********************\n",
      "Pod user-timeline-service-65d5766796-f2b7h is running at node: k8s-worker-3\n",
      "Pod user-timeline-service-65d5766796-f2b7h has been moved to node k8s-worker-8\n",
      "********************After scheduling the pod ********************\n",
      "New pod name is: user-timeline-service-65d5766796-f2b7h\n"
     ]
    }
   ],
   "source": [
    "# change pod to another node        \n",
    "change_node_for_pod(pod_name=\"user-timeline-service-65d5766796-f2b7h\", pod_nameapce=\"social-network\" , new_assigned_node_name=\"k8s-worker-8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Before scheduling the pod ********************\n",
      "Pod post-storage-mongodb-5d7bfcd455-spqgt is running at node: k8s-worker-1\n",
      "Pod post-storage-mongodb-5d7bfcd455-spqgt has been moved to node k8s-worker-9\n",
      "********************After scheduling the pod ********************\n",
      "New pod name is: post-storage-mongodb-5d7bfcd455-spqgt\n"
     ]
    }
   ],
   "source": [
    "# change pod to another node        \n",
    "change_node_for_pod(pod_name=\"post-storage-mongodb-5d7bfcd455-spqgt\", pod_nameapce=\"social-network\" , new_assigned_node_name=\"k8s-worker-9\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Before scheduling the pod ********************\n",
      "Pod url-shorten-service-6d8bbf75f8-fw7dk is running at node: k8s-worker-9\n",
      "Pod url-shorten-service-6d8bbf75f8-fw7dk has been moved to node k8s-worker-3\n",
      "********************After scheduling the pod ********************\n",
      "New pod name is: url-shorten-service-6d8bbf75f8-fw7dk\n",
      "********************Before scheduling the pod ********************\n",
      "Pod user-service-74685b9465-zxc6q is running at node: k8s-worker-8\n",
      "Pod user-service-74685b9465-zxc6q has been moved to node k8s-worker-2\n",
      "********************After scheduling the pod ********************\n",
      "New pod name is: user-service-74685b9465-zxc6q\n",
      "********************Before scheduling the pod ********************\n",
      "Pod social-graph-redis-7d9b494f66-tnhk8 is running at node: k8s-worker-7\n",
      "Pod social-graph-redis-7d9b494f66-tnhk8 has been moved to node k8s-worker-1\n",
      "********************After scheduling the pod ********************\n",
      "New pod name is: social-graph-redis-7d9b494f66-tnhk8\n",
      "********************Before scheduling the pod ********************\n",
      "Pod unique-id-service-6b88dd4658-4bhpf is running at node: k8s-worker-8\n",
      "Pod unique-id-service-6b88dd4658-4bhpf has been moved to node k8s-worker-2\n",
      "********************After scheduling the pod ********************\n",
      "New pod name is: unique-id-service-6b88dd4658-4bhpf\n",
      "********************Before scheduling the pod ********************\n",
      "Pod media-frontend-75b5d868d7-f7rks is running at node: k8s-worker-6\n",
      "Pod media-frontend-75b5d868d7-f7rks has been moved to node k8s-worker-2\n",
      "********************After scheduling the pod ********************\n",
      "New pod name is: media-frontend-75b5d868d7-f7rks\n"
     ]
    }
   ],
   "source": [
    "change_node_for_pod(pod_name=\"url-shorten-service-6d8bbf75f8-fw7dk\", pod_nameapce=\"social-network\" , new_assigned_node_name=\"k8s-worker-3\")\n",
    "change_node_for_pod(pod_name=\"user-service-74685b9465-zxc6q\", pod_nameapce=\"social-network\" , new_assigned_node_name=\"k8s-worker-2\")\n",
    "change_node_for_pod(pod_name=\"social-graph-redis-7d9b494f66-tnhk8\", pod_nameapce=\"social-network\" , new_assigned_node_name=\"k8s-worker-1\")\n",
    "change_node_for_pod(pod_name=\"unique-id-service-6b88dd4658-4bhpf\", pod_nameapce=\"social-network\" , new_assigned_node_name=\"k8s-worker-2\")\n",
    "\n",
    "change_node_for_pod(pod_name=\"media-frontend-75b5d868d7-f7rks\", pod_nameapce=\"social-network\" , new_assigned_node_name=\"k8s-worker-2\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Before scheduling the pod ********************\n",
      "Pod post-storage-memcached-675b5c57bd-lsskt is running at node: k8s-worker-9\n",
      "Pod post-storage-memcached-675b5c57bd-lsskt has been moved to node k8s-worker-3\n",
      "********************After scheduling the pod ********************\n",
      "New pod name is: post-storage-memcached-675b5c57bd-lsskt\n"
     ]
    }
   ],
   "source": [
    "change_node_for_pod(pod_name=\"post-storage-memcached-675b5c57bd-lsskt\", pod_nameapce=\"social-network\" , new_assigned_node_name=\"k8s-worker-3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Before scheduling the pod ********************\n",
      "Pod jaeger-7455bdbc47-2zqsm is running at node: k8s-worker-7\n",
      "Pod jaeger-7455bdbc47-2zqsm has been moved to node k8s-worker-1\n",
      "********************After scheduling the pod ********************\n",
      "New pod name is: jaeger-7455bdbc47-2zqsm\n"
     ]
    }
   ],
   "source": [
    "change_node_for_pod(pod_name=\"jaeger-7455bdbc47-2zqsm\", pod_nameapce=\"social-network\" , new_assigned_node_name=\"k8s-worker-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Before scheduling the pod ********************\n",
      "Pod media-service-7848df64c4-gpqn8 is running at node: k8s-worker-8\n",
      "Pod media-service-7848df64c4-gpqn8 has been moved to node k8s-worker-2\n",
      "********************After scheduling the pod ********************\n",
      "New pod name is: media-service-7848df64c4-gpqn8\n"
     ]
    }
   ],
   "source": [
    "change_node_for_pod(pod_name=\"media-service-7848df64c4-gpqn8\", pod_nameapce=\"social-network\" , new_assigned_node_name=\"k8s-worker-2\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
