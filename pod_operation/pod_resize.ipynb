{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client, config\n",
    "\n",
    "# get the capacity and allocatable resources of a node\n",
    "def get_node_resources(node_name):\n",
    "    config.load_kube_config()\n",
    "    api = client.CoreV1Api()\n",
    "    node = api.read_node(node_name)\n",
    "    print(\"node.status.capacity=\",node.status.capacity)\n",
    "    print(\"node.status.allocatable=\",node.status.allocatable)\n",
    "    \n",
    "    return node.status.capacity, node.status.allocatable\n",
    "\n",
    "#convert different memory units to bytes:\n",
    "def convert_memory_to_bytes(memory_str):\n",
    "    if 'Gi' in memory_str:\n",
    "        return int(memory_str.replace('Gi', '')) * 1024 * 1024 * 1024\n",
    "    elif 'Mi' in memory_str:\n",
    "        return int(memory_str.replace('Mi', '')) * 1024 * 1024\n",
    "    elif 'Ki' in memory_str:\n",
    "        return int(memory_str.replace('Ki', '')) * 1024\n",
    "    else:\n",
    "        return int(memory_str)\n",
    "\n",
    "#convert different memory units to Mega Bytes:\n",
    "def convert_memory_to_MiB(memory_str):\n",
    "    if 'Gi' in memory_str:\n",
    "        return int(memory_str.replace('Gi', '')) * 1024\n",
    "    elif 'Mi' in memory_str:\n",
    "        return int(memory_str.replace('Mi', ''))\n",
    "    else:\n",
    "        print(\"Please Check: Memory unit error!\")\n",
    "        return int(memory_str)\n",
    "\n",
    "# sums up the resource requests and limits for all pods running on a given node\n",
    "# remove limits []]\n",
    "def sum_pod_resources_on_node(node_name):\n",
    "    config.load_kube_config() # Load the kube config to authendicate and interact with the cluster\n",
    "    api = client.CoreV1Api()\n",
    "\n",
    "    pod_list = api.list_pod_for_all_namespaces(watch=False) # Get a list of all pods in the cluster\n",
    "    total_cpu_request, total_memory_request = 0, 0\n",
    "    total_cpu_limit, total_memory_limit = 0, 0\n",
    "\n",
    "    for pod in pod_list.items:\n",
    "        if pod.spec.node_name == node_name:\n",
    "            for container in pod.spec.containers:\n",
    "                if container.resources.requests:\n",
    "                    total_cpu_request += int(container.resources.requests.get('cpu', '0m').replace('m', ''))\n",
    "                    total_memory_request += int(container.resources.requests.get('memory', '0Mi').replace('Mi', ''))\n",
    "                if container.resources.limits:\n",
    "                    total_cpu_limit += int(container.resources.limits.get('cpu', '0m').replace('m', ''))\n",
    "                    total_memory_limit += convert_memory_to_MiB(container.resources.limits.get('memory', '0Mi'))\n",
    "    \n",
    "\n",
    "    return total_cpu_request, total_memory_request, total_cpu_limit, total_memory_limit\n",
    "\n",
    "# vertically scale the resources of a specific pod\n",
    "def vertical_scale_pod_resources2(pod_name, namespace, new_cpu_request, new_cpu_limit, new_memory_request, new_memory_limit):\n",
    "    # Load the kube config\n",
    "    config.load_kube_config()\n",
    "    # Create an CoreV1Api instance\n",
    "    api = client.CoreV1Api()\n",
    "\n",
    "    # Fetch the existing pod\n",
    "    pod = api.read_namespaced_pod(pod_name, namespace)\n",
    "    container = pod.spec.containers[0] # Get the first container in the pod; change to differnet containers index if needed\n",
    "\n",
    "    # Get the node name from the pod spec\n",
    "    node_name = pod.spec.node_name\n",
    "\n",
    "    node_capacity, node_allocatable = get_node_resources(node_name)\n",
    "    node_cpu_allocatable_millicores = int(node_allocatable['cpu'].replace('m', ''))*1000 # convert to millicores\n",
    "    node_memory_allocatable_mebibytes = int(node_allocatable['memory'].replace('Ki', ''))/1024  # convert to MiB\n",
    "    \n",
    "    total_cpu_request, total_memory_request, total_cpu_limit, total_memory_limit = sum_pod_resources_on_node(node_name)\n",
    "\n",
    "    new_cpu_request_millicores = int(new_cpu_request.replace('m', ''))\n",
    "    new_cpu_limit_millicores = int(new_cpu_limit.replace('m', ''))\n",
    "    new_memory_request_mebibytes = int(new_memory_request.replace('Mi', ''))\n",
    "    new_memory_limit_mebibytes = int(new_memory_limit.replace('Mi', ''))\n",
    "\n",
    "    # Check whether the node can accommodate the new requests and limits\n",
    "    if (total_cpu_request + new_cpu_request_millicores <= node_cpu_allocatable_millicores and\n",
    "        total_memory_request + new_memory_request_mebibytes <= node_memory_allocatable_mebibytes and\n",
    "        total_cpu_limit + new_cpu_limit_millicores <= node_cpu_allocatable_millicores and\n",
    "        total_memory_limit + new_memory_limit_mebibytes <= node_memory_allocatable_mebibytes):\n",
    "\n",
    "        if not container.resources:\n",
    "            container.resources = client.V1ResourceRequirements()\n",
    "\n",
    "        container.resources.requests = {\n",
    "            \"cpu\": new_cpu_request,\n",
    "            \"memory\": new_memory_request\n",
    "        }\n",
    "\n",
    "        container.resources.limits = {\n",
    "            \"cpu\": new_cpu_limit,\n",
    "            \"memory\": new_memory_limit\n",
    "        }\n",
    "\n",
    "        # Apply the updated pod spec\n",
    "        api.patch_namespaced_pod(pod_name, namespace, pod)\n",
    "\n",
    "        print(f\"Successfully scaled the resources for pod {pod_name}\")\n",
    "    else:\n",
    "        print(\"Insufficient node resources for the requested scaling operation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vertically scale the resources of pods from a deployment\n",
    "def vertical_scale_pod_resources(deployment_name, namespace, new_cpu_request, new_cpu_limit, new_memory_request, new_memory_limit, node_name):\n",
    "    # Load the kube config\n",
    "    config.load_kube_config()\n",
    "    # Create an AppsV1Api instance\n",
    "    api = client.AppsV1Api()\n",
    "\n",
    "    # Fetch the existing deployment\n",
    "    deployment = api.read_namespaced_deployment(deployment_name, namespace)\n",
    "    container = deployment.spec.template.spec.containers[0]\n",
    "\n",
    "    node_capacity, node_allocatable = get_node_resources(node_name)\n",
    "    node_cpu_allocatable_millicores = int(node_allocatable['cpu'].replace('m', ''))*1000 # convert to millicores\n",
    "    node_memory_allocatable_mebibytes = int(node_allocatable['memory'].replace('Ki', ''))/1024  # convert to MiB\n",
    "    \n",
    "    total_cpu_request, total_memory_request, total_cpu_limit, total_memory_limit = sum_pod_resources_on_node(node_name)\n",
    "\n",
    "    new_cpu_request_millicores = int(new_cpu_request.replace('m', ''))\n",
    "    new_cpu_limit_millicores = int(new_cpu_limit.replace('m', ''))\n",
    "    new_memory_request_mebibytes = int(new_memory_request.replace('Mi', ''))\n",
    "    new_memory_limit_mebibytes = int(new_memory_limit.replace('Mi', ''))\n",
    "\n",
    "    # Check whether the node can accommodate the new requests and limits\n",
    "    if (total_cpu_request + new_cpu_request_millicores <= node_cpu_allocatable_millicores and\n",
    "        total_memory_request + new_memory_request_mebibytes <= node_memory_allocatable_mebibytes and\n",
    "        total_cpu_limit + new_cpu_limit_millicores <= node_cpu_allocatable_millicores and\n",
    "        total_memory_limit + new_memory_limit_mebibytes <= node_memory_allocatable_mebibytes):\n",
    "\n",
    "        if not container.resources:\n",
    "            container.resources = client.V1ResourceRequirements()\n",
    "\n",
    "        container.resources.requests = {\n",
    "            \"cpu\": new_cpu_request,\n",
    "            \"memory\": new_memory_request\n",
    "        }\n",
    "\n",
    "        container.resources.limits = {\n",
    "            \"cpu\": new_cpu_limit,\n",
    "            \"memory\": new_memory_limit\n",
    "        }\n",
    "\n",
    "        # Apply the updated deployment spec\n",
    "        api.patch_namespaced_deployment(deployment_name, namespace, deployment)\n",
    "\n",
    "        print(f\"Successfully scaled the resources for deployment {deployment_name}\")\n",
    "    else:\n",
    "        print(\"Insufficient node resources for the requested scaling operation.\")\n",
    "        ######################### Conditio  Check, why failed to scale ##########################################\n",
    "        \n",
    "        node_cpu_allocatable_millicores = int(node_allocatable['cpu'].replace('m', ''))*1000 # convert to millicores\n",
    "        node_memory_allocatable_mebibytes = int(node_allocatable['memory'].replace('Ki', ''))/1024  # convert to MiB\n",
    "\n",
    "        # Calculate the new total values after scaling\n",
    "        new_total_cpu_request = total_cpu_request + new_cpu_request_millicores\n",
    "        new_total_memory_request = total_memory_request + new_memory_request_mebibytes\n",
    "        new_total_cpu_limit = total_cpu_limit + new_cpu_limit_millicores\n",
    "        new_total_memory_limit = total_memory_limit + new_memory_limit_mebibytes\n",
    "\n",
    "        # Printout for debugging\n",
    "        print(f\"New total CPU request: {new_total_cpu_request} (Available: {node_cpu_allocatable_millicores})\")\n",
    "        print(f\"New total Memory request: {new_total_memory_request} (Available: {node_memory_allocatable_mebibytes})\")\n",
    "        print(f\"New total CPU limit: {new_total_cpu_limit} (Available: {node_cpu_allocatable_millicores})\")\n",
    "        print(f\"New total Memory limit: {new_total_memory_limit} (Available: {node_memory_allocatable_mebibytes})\")\n",
    "\n",
    "        # Check conditions\n",
    "        cpu_request_condition = new_total_cpu_request <= node_cpu_allocatable_millicores\n",
    "        memory_request_condition = new_total_memory_request <= node_memory_allocatable_mebibytes\n",
    "        cpu_limit_condition = new_total_cpu_limit <= node_cpu_allocatable_millicores\n",
    "        memory_limit_condition = new_total_memory_limit <= node_memory_allocatable_mebibytes\n",
    "\n",
    "        # Printout for debugging which condition fails\n",
    "        if not cpu_request_condition:\n",
    "            print(\"Condition failed: CPU Request exceeds available allocatable CPU.\")\n",
    "        if not memory_request_condition:\n",
    "            print(\"Condition failed: Memory Request exceeds available allocatable memory.\")\n",
    "        if not cpu_limit_condition:\n",
    "            print(\"Condition failed: CPU Limit exceeds available allocatable CPU.\")\n",
    "        if not memory_limit_condition:\n",
    "            print(\"Condition failed: Memory Limit exceeds available allocatable memory.\")\n",
    "\n",
    "        # Final condition check\n",
    "        if cpu_request_condition and memory_request_condition and cpu_limit_condition and memory_limit_condition:\n",
    "            # Proceed with the scaling operation\n",
    "            print(\"All conditions met. Proceeding with scaling.\")\n",
    "        else:\n",
    "            print(\"Scaling operation aborted. One or more conditions not met.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test usage by scaling pod resources via deployment\n",
    "deployment_name = \"nginx-deployment\"\n",
    "namespace = \"nginx-app\"\n",
    "node_name = \"microk8snode1\"\n",
    "\n",
    "new_cpu_request = \"20m\" # 20 millicores\n",
    "new_cpu_limit = \"40m\"\n",
    "new_memory_request = \"16Mi\" # 16 Mebibytes\n",
    "new_memory_limit = \"30Mi\"\n",
    "\n",
    "vertical_scale_pod_resources(deployment_name, namespace, new_cpu_request, new_cpu_limit, new_memory_request, new_memory_limit, node_name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
