{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: k8s-worker-5, Number of Pods in 'social-network' namespace: 4\n",
      "Node: k8s-worker-7, Number of Pods in 'social-network' namespace: 4\n",
      "Node: k8s-worker-8, Number of Pods in 'social-network' namespace: 4\n",
      "Node: k8s-worker-3, Number of Pods in 'social-network' namespace: 6\n",
      "Node: k8s-worker-6, Number of Pods in 'social-network' namespace: 3\n",
      "Node: k8s-worker-4, Number of Pods in 'social-network' namespace: 4\n",
      "Node: k8s-worker-9, Number of Pods in 'social-network' namespace: 2\n"
     ]
    }
   ],
   "source": [
    "# summarize the pods number and the distributions in each node\n",
    "\n",
    "from kubernetes import client, config\n",
    "\n",
    "# Load Kubernetes cluster configuration\n",
    "config.load_kube_config()\n",
    "\n",
    "# Create a core V1 client\n",
    "v1 = client.CoreV1Api()\n",
    "\n",
    "# Define the namespace to filter\n",
    "namespace_to_filter = \"social-network\"\n",
    "\n",
    "# Get all pods in the specific namespace\n",
    "pods = v1.list_namespaced_pod(namespace=namespace_to_filter, watch=False)\n",
    "\n",
    "# Create a dictionary to count the pods per node\n",
    "pod_count_per_node = {}\n",
    "\n",
    "# Count pods by node in the specified namespace\n",
    "for pod in pods.items:\n",
    "    node = pod.spec.node_name\n",
    "    if node not in pod_count_per_node:\n",
    "        pod_count_per_node[node] = 0\n",
    "    pod_count_per_node[node] += 1\n",
    "\n",
    "# Print the results\n",
    "for node, count in pod_count_per_node.items():\n",
    "    print(f\"Node: {node}, Number of Pods in '{namespace_to_filter}' namespace: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running wrk for different rates: 100%|██████████| 7/7 [00:00<00:00, 2047.86it/s]\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "# Function to execute wrk command\n",
    "def run_wrk(url, script_path, duration, rate, data_dir):\n",
    "    current_time_str = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "    result_filename = f\"{data_dir}/{current_time_str}_{rate}_{duration}.txt\"\n",
    "    command = f\"/home/ubuntu/DeathStarBench/wrk2/wrk -D exp -t2 -c100 -d{duration} -L -s {script_path} {url} -R{rate}\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    \n",
    "    with open(result_filename, 'w') as file:\n",
    "        file.write(result.stdout)\n",
    "    \n",
    "    print(f\"Results for rate {rate} saved to {result_filename}\")\n",
    "    return result_filename\n",
    "\n",
    "# Function to parse wrk output\n",
    "\n",
    "\n",
    "def parse_wrk_output(filename):\n",
    "    latencies = []\n",
    "    recording = False  # Flag to start recording latencies\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            # Start recording after the \"Detailed Percentile spectrum:\" line\n",
    "            if line.startswith(\"  Detailed Percentile spectrum:\"):\n",
    "                recording = True\n",
    "                continue  # Skip the header line\n",
    "\n",
    "            # Stop recording at the summary statistics section\n",
    "            if line.startswith(\"#[Mean\"):\n",
    "                break\n",
    "\n",
    "            if recording:\n",
    "                # Example line: \"       2.037     0.000000            1         1.00\"\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 2:\n",
    "                    try:\n",
    "                        # Assuming latencies are reported in milliseconds\n",
    "                        latency = float(parts[0])  # Convert latency value to float\n",
    "                        latencies.append(latency)\n",
    "                    except ValueError:\n",
    "                        # Handle the case where conversion to float fails\n",
    "                        continue\n",
    "\n",
    "    return latencies\n",
    "\n",
    "# Function to plot CDF\n",
    "def plot_cdf(data, filename):\n",
    "    sorted_data = np.sort(data)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.step(sorted_data, np.linspace(0, 1, len(sorted_data), endpoint=False), where='post')\n",
    "    plt.xlabel('Response Time (ms)')\n",
    "    plt.ylabel('CDF')\n",
    "    plt.title('CDF of Response Times')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "# Function to plot Violin Plot\n",
    "def plot_violin(latency_data, request_rates, data_dir):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    data_to_plot = [latencies for _, latencies in latency_data.items() if latencies]\n",
    "    sns.violinplot(data=data_to_plot)\n",
    "    plt.xticks(np.arange(len(request_rates)), labels=[str(rate) for rate in request_rates])\n",
    "    plt.xlabel('Request Rate')\n",
    "    plt.ylabel('Response Time (ms)')\n",
    "    plt.title('Response Time Distribution by Request Rate')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    current_time_str = datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "    filename = f\"{data_dir}/violin_plot_{current_time_str}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    print(f\"Saved violin plot to {filename}\")\n",
    "\n",
    "\n",
    "data_dir = \"/home/ubuntu/ms_scheduling/social_net/perf_testing/data/\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "url = \"http://nginx-thrift.social-network.svc.cluster.local:8080/wrk2-api/home-timeline/read\"\n",
    "script_path = \"/home/ubuntu/DeathStarBench/socialNetwork/wrk2/scripts/social-network/read-home-timeline.lua\"\n",
    "duration = \"10m\"\n",
    "request_rates = [300, 500, 1000, 1500, 2000, 3000, 5000]\n",
    "result_files = []\n",
    "latency_data = {}\n",
    "filename = ['202403291239_300_10m.txt','202403291249_500_10m.txt', '202403291259_1000_10m.txt', '202403291309_1500_10m.txt', '202403291319_2000_10m.txt',\n",
    "                '202403291329_3000_10m.txt', '202403291339_5000_10m.txt']\n",
    "i=0\n",
    "for rate in tqdm(request_rates, desc=\"Running wrk for different rates\"):\n",
    "    # filename = run_wrk(url, script_path, duration, rate, data_dir)\n",
    "    \n",
    "\n",
    "    latencies = parse_wrk_output(data_dir+filename[i])\n",
    "    latency_data[rate] = latencies\n",
    "    i=i+1\n",
    "    # if latencies:\n",
    "    #     plot_filename = filename.replace('.txt', '_cdf.png')\n",
    "    #     plot_cdf(latencies, plot_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved violin plot to /home/ubuntu/ms_scheduling/social_net/perf_testing/data//violin_plot_202403300627.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if latency_data:\n",
    "    plot_violin(latency_data, request_rates, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running wrk for different rates: 100%|██████████| 2/2 [00:00<00:00,  7.00it/s]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
