{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client, config, watch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from prometheus_api_client import PrometheusConnect\n",
    "\n",
    "# from datetime import datetime, timedelta\n",
    "import time\n",
    "from difflib import diff_bytes\n",
    "import matplotlib.pyplot as plt\n",
    "import kubernetes.client.models.v1_pod as v1pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'metric': {'__name__': 'instance:node_network_receive_bytes:rate:sum', 'instance': '172.26.128.228:9100'}, 'value': [1709723262.259, '141242.7']}, {'metric': {'__name__': 'instance:node_network_receive_bytes:rate:sum', 'instance': '172.26.128.30:9100'}, 'value': [1709723262.259, '4273.426666666666']}, {'metric': {'__name__': 'instance:node_network_receive_bytes:rate:sum', 'instance': '172.26.130.22:9100'}, 'value': [1709723262.259, '82282.89333333333']}, {'metric': {'__name__': 'instance:node_network_receive_bytes:rate:sum', 'instance': '172.26.130.82:9100'}, 'value': [1709723262.259, '4657.173333333333']}, {'metric': {'__name__': 'instance:node_network_receive_bytes:rate:sum', 'instance': '172.26.132.142:9100'}, 'value': [1709723262.259, '13537.453333333333']}, {'metric': {'__name__': 'instance:node_network_receive_bytes:rate:sum', 'instance': '172.26.132.241:9100'}, 'value': [1709723262.259, '5554.799999999999']}, {'metric': {'__name__': 'instance:node_network_receive_bytes:rate:sum', 'instance': '172.26.132.91:9100'}, 'value': [1709723262.259, '5265.006666666666']}, {'metric': {'__name__': 'instance:node_network_receive_bytes:rate:sum', 'instance': '172.26.133.118:9100'}, 'value': [1709723262.259, '7626.166666666666']}, {'metric': {'__name__': 'instance:node_network_receive_bytes:rate:sum', 'instance': '172.26.133.31:9100'}, 'value': [1709723262.259, '4756.106666666667']}, {'metric': {'__name__': 'instance:node_network_receive_bytes:rate:sum', 'instance': '172.26.133.55:9100'}, 'value': [1709723262.259, '3933.513333333333']}]\n"
     ]
    }
   ],
   "source": [
    "# test the connecting with Prometheus\n",
    "# Kubernetes Config\n",
    "config.load_kube_config()\n",
    "v1 = client.CoreV1Api()\n",
    "\n",
    "# Prometheus Config\n",
    "#prom_url = \"http://<PROMETHEUS_SERVER_IP>:<PORT>\"\n",
    "# prom_url = \"http://10.110.188.57:9090\"\n",
    "prom_url = \"http://prometheus-stack-kube-prom-prometheus.monitoring.svc.cluster.local:9090\"\n",
    "prom = PrometheusConnect(url=prom_url, disable_ssl=True)\n",
    "#test prom connection\n",
    "response = prom.custom_query(query=\"instance:node_network_receive_bytes:rate:sum\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k8s-master': '172.26.128.228', 'k8s-worker-1': '172.26.128.30', 'k8s-worker-2': '172.26.132.91', 'k8s-worker-3': '172.26.133.31', 'k8s-worker-4': '172.26.132.241', 'k8s-worker-5': '172.26.132.142', 'k8s-worker-6': '172.26.133.55', 'k8s-worker-7': '172.26.130.22', 'k8s-worker-8': '172.26.130.82', 'k8s-worker-9': '172.26.133.118'}\n"
     ]
    }
   ],
   "source": [
    "# find all nodes and its ip in the cluster, store the nodename and ip in a dictionary\n",
    "node_ip = {}\n",
    "nodes = v1.list_node()\n",
    "for node in nodes.items:\n",
    "    for address in node.status.addresses:\n",
    "        if address.type == \"InternalIP\":\n",
    "            node_ip[node.metadata.name] = address.address\n",
    "print(node_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# find all nodes and its ip in the cluster, store the nodename and ip in a dictionary\n",
    "node_ip = {}\n",
    "nodes = v1.list_node()\n",
    "for node in nodes.items:\n",
    "    for address in node.status.addresses:\n",
    "        if address.type == \"InternalIP\":\n",
    "            node_ip[node.metadata.name] = address.address\n",
    "print(node_ip)\n",
    "\n",
    "# URL of your Prometheus server\n",
    "PROMETHEUS = \"http://prometheus-stack-kube-prom-prometheus.monitoring.svc.cluster.local:9090\"\n",
    "\n",
    "# Your Prometheus query\n",
    "query = 'instance:node_network_receive_bytes:rate:sum'\n",
    "# query = 'sum(rate(node_network_receive_bytes_total[1m])) * 60'\n",
    "\n",
    "\n",
    "# Construct the full URL for the query\n",
    "url = f'{PROMETHEUS}/api/v1/query'\n",
    "\n",
    "# Parameters for the query\n",
    "params = {\n",
    "    'query': query,\n",
    "    # Optionally, you can specify the exact time you want to query for\n",
    "    # 'time': '2024-02-27T12:00:00Z',\n",
    "}\n",
    "\n",
    "\n",
    "def find_loweset_bandwidth():\n",
    "     # Make the HTTP GET request\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    node_bandwidth = {}\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        # Print the entire response\n",
    "        # print(result)\n",
    "        # Extract and print just the result data\n",
    "        data = result.get('data', {}).get('result', [])\n",
    "        if data:\n",
    "            for item in data:\n",
    "                # Assuming the query returns vector results, iterate and print\n",
    "                metric_name = item.get('metric', {}).get('__name__', 'Unknown metric')\n",
    "                instance_name = item.get('metric', {}).get('instance', 'Unknown instance')\n",
    "                value = item.get('value', [])[1]  # The value is a [timestamp, value] pair\n",
    "                # print(f'node {instance_name} has network bandith with :{value}')\n",
    "                \n",
    "                # save the instance name and value to a dictionary\n",
    "                instance_ip = instance_name.split(\":\")[0] # get the ip of the instance, Eg: change this string \"172.26.128.228:9100'\" into \"172.26.128.228\"\n",
    "                node_bandwidth[instance_ip] = float(value) # change string value into float\n",
    "        else:\n",
    "            print(\"No data returned\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data: {response.status_code} - {response.text}\")\n",
    "    print(node_bandwidth)\n",
    "    \n",
    "    \n",
    "    \n",
    "    lowest_bandwidth = node_bandwidth[list(node_bandwidth.keys())[0]]\n",
    "    # print(lowest_bandwidth)\n",
    "    lowest_bandwidth_node = \"\"\n",
    "    for node, bandwidth in node_bandwidth.items():\n",
    "        if bandwidth < lowest_bandwidth:\n",
    "            lowest_bandwidth = bandwidth\n",
    "            lowest_bandwidth_node = node\n",
    "            \n",
    "    return lowest_bandwidth_node, lowest_bandwidth\n",
    "\n",
    "#find the node name with lowest bandwidth\n",
    "# lowest_bandwidth_node, lowest_bandwidth = find_loweset_bandwidth(node_bandwidth)\n",
    "# print(f\"the node with lowest bandwidth is {lowest_bandwidth_node} with bandwidth {lowest_bandwidth}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create  a pod on a given node and namespace\n",
    "def create_pod(name, namespace, image, cpu_request, memory_request, node_name):\n",
    "    # Configure the Kubernetes client\n",
    "    config.load_kube_config()\n",
    "\n",
    "    # Create API clients\n",
    "    v1 = client.CoreV1Api()\n",
    "\n",
    "    # Define the Pod spec\n",
    "    pod = v1pod.V1Pod()\n",
    "    # specify the nodename for the pod\n",
    "    \n",
    "    pod.metadata = client.V1ObjectMeta(name=name, namespace=namespace)\n",
    "    pod.spec = client.V1PodSpec(containers=[client.V1Container(name=name, image=image, resources=client.V1ResourceRequirements(\n",
    "        requests={\"cpu\": cpu_request, \"memory\": memory_request}))], node_name=node_name)\n",
    "\n",
    "    # Create the Pod\n",
    "    v1.create_namespaced_pod(namespace=namespace, body=pod)\n",
    "\n",
    "    print(f\"Created Pod {name} in namespace {namespace} with image {image} and resource requests: CPU={cpu_request}, Memory={memory_request} on node {node_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'172.26.128.228': 146217.84, '172.26.128.30': 4002.973333333333, '172.26.130.22': 81927.04666666665, '172.26.130.82': 5248.139999999999, '172.26.132.142': 13618.78, '172.26.132.241': 5502.466666666667, '172.26.132.91': 6840.44, '172.26.133.118': 7263.873333333333, '172.26.133.31': 5801.88, '172.26.133.55': 4056.9933333333333}\n",
      "the node with lowest bandwidth is 172.26.128.30 with bandwidth 4002.973333333333\n",
      "Created Pod test-pod-1 in namespace nginx-app-test with image nginx and resource requests: CPU=100m, Memory=128Mi on node k8s-worker-1\n",
      "{'172.26.128.228': 146724.74, '172.26.128.30': 6885.033333333332, '172.26.130.22': 82682.95999999999, '172.26.130.82': 7169.473333333333, '172.26.132.142': 13758.2, '172.26.132.241': 5569.099999999999, '172.26.132.91': 7488.719999999999, '172.26.133.118': 7825.179999999999, '172.26.133.31': 5319.113333333333, '172.26.133.55': 5631.54}\n",
      "the node with lowest bandwidth is 172.26.133.31 with bandwidth 5319.113333333333\n",
      "Created Pod test-pod-2 in namespace nginx-app-test with image nginx and resource requests: CPU=100m, Memory=128Mi on node k8s-worker-3\n",
      "{'172.26.128.228': 155374.9933333333, '172.26.128.30': 7112.561655555555, '172.26.130.22': 81657.16666666664, '172.26.130.82': 7386.233333333333, '172.26.132.142': 13673.313333333332, '172.26.132.241': 6350.733333333333, '172.26.132.91': 7278.779999999999, '172.26.133.118': 7842.506666666666, '172.26.133.31': 5832.026666666667, '172.26.133.55': 5783.08}\n",
      "the node with lowest bandwidth is 172.26.133.55 with bandwidth 5783.08\n",
      "Created Pod test-pod-3 in namespace nginx-app-test with image nginx and resource requests: CPU=100m, Memory=128Mi on node k8s-worker-6\n",
      "{'172.26.128.228': 155104.56666666662, '172.26.128.30': 6499.019606512334, '172.26.130.22': 79771.98666666666, '172.26.130.82': 7827.493333333332, '172.26.132.142': 13801.553333333331, '172.26.132.241': 5583.353333333333, '172.26.132.91': 7637.593333333332, '172.26.133.118': 7668.733333333332, '172.26.133.31': 6044.528286111111, '172.26.133.55': 6957.599999999999}\n",
      "the node with lowest bandwidth is 172.26.132.241 with bandwidth 5583.353333333333\n",
      "Created Pod test-pod-4 in namespace nginx-app-test with image nginx and resource requests: CPU=100m, Memory=128Mi on node k8s-worker-4\n",
      "{'172.26.128.228': 139102.42, '172.26.128.30': 3891.193333333333, '172.26.130.22': 80246.08, '172.26.130.82': 5609.726666666666, '172.26.132.142': 13657.246666666666, '172.26.132.241': 5761.152688888888, '172.26.132.91': 7066.926666666667, '172.26.133.118': 7692.24, '172.26.133.31': 6723.776635185185, '172.26.133.55': 5250.238008333334}\n",
      "the node with lowest bandwidth is 172.26.128.30 with bandwidth 3891.193333333333\n",
      "Created Pod test-pod-5 in namespace nginx-app-test with image nginx and resource requests: CPU=100m, Memory=128Mi on node k8s-worker-1\n",
      "{'172.26.128.228': 134068.47999999995, '172.26.128.30': 4665.36, '172.26.130.22': 80521.40666666666, '172.26.130.82': 5757.873333333333, '172.26.132.142': 13683.9, '172.26.132.241': 6668.668891358023, '172.26.132.91': 7175.166666666666, '172.26.133.118': 7522.173333333332, '172.26.133.31': 6029.326666666666, '172.26.133.55': 5347.953333333333}\n",
      "the node with lowest bandwidth is 172.26.128.30 with bandwidth 4665.36\n",
      "Created Pod test-pod-6 in namespace nginx-app-test with image nginx and resource requests: CPU=100m, Memory=128Mi on node k8s-worker-1\n",
      "{'172.26.128.228': 131811.31999999998, '172.26.128.30': 5984.885816666666, '172.26.130.22': 80706.02, '172.26.130.82': 4982.613333333333, '172.26.132.142': 13518.313333333332, '172.26.132.241': 6002.873333333333, '172.26.132.91': 6531.706666666666, '172.26.133.118': 7380.1866666666665, '172.26.133.31': 5733.486666666667, '172.26.133.55': 3974.5466666666666}\n",
      "the node with lowest bandwidth is 172.26.133.55 with bandwidth 3974.5466666666666\n",
      "Created Pod test-pod-7 in namespace nginx-app-test with image nginx and resource requests: CPU=100m, Memory=128Mi on node k8s-worker-6\n",
      "{'172.26.128.228': 138313.80000000002, '172.26.128.30': 6207.278724999999, '172.26.130.22': 81052.71999999999, '172.26.130.82': 5108.473333333333, '172.26.132.142': 13531.853333333334, '172.26.132.241': 4888.786666666667, '172.26.132.91': 5920.226666666666, '172.26.133.118': 7337.659999999999, '172.26.133.31': 4861.693333333334, '172.26.133.55': 4903.693333333333}\n",
      "the node with lowest bandwidth is 172.26.133.31 with bandwidth 4861.693333333334\n",
      "Created Pod test-pod-8 in namespace nginx-app-test with image nginx and resource requests: CPU=100m, Memory=128Mi on node k8s-worker-3\n",
      "{'172.26.128.228': 138123.97333333333, '172.26.128.30': 4787.092908333333, '172.26.130.22': 81195.25333333331, '172.26.130.82': 5297.206666666666, '172.26.132.142': 18278.83333333333, '172.26.132.241': 5594.500000000001, '172.26.132.91': 6118.206666666666, '172.26.133.118': 7603.306666666666, '172.26.133.31': 5822.113333333333, '172.26.133.55': 5079.491341666666}\n",
      "the node with lowest bandwidth is 172.26.128.30 with bandwidth 4787.092908333333\n",
      "Created Pod test-pod-9 in namespace nginx-app-test with image nginx and resource requests: CPU=100m, Memory=128Mi on node k8s-worker-1\n"
     ]
    }
   ],
   "source": [
    "# create pods with different names with loop for testing, eaching creation pod will take 60 seconds\n",
    "for i in range(1,10,1):\n",
    "    a, b =find_loweset_bandwidth()\n",
    "    print(f\"the node with lowest bandwidth is {a} with bandwidth {b}\")\n",
    "    # find the nodename based on the ip\n",
    "    for node, ip in node_ip.items():\n",
    "        if ip == a:\n",
    "            pod_binding_node = node\n",
    "    \n",
    "    create_pod(name=f\"test-pod-{i}\", namespace=\"nginx-app-test\", image=\"nginx\", cpu_request=\"100m\", memory_request=\"128Mi\", node_name=pod_binding_node)\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "\n",
    "while(True):\n",
    "    sleep(3) # sleep for 5 seconds\n",
    "    a, b =find_loweset_bandwidth()\n",
    "    print(f\"the node with lowest bandwidth is {a} with bandwidth {b}\")\n",
    "    # find the nodename based on the ip\n",
    "    for node, ip in node_ip.items():\n",
    "        if ip == a:\n",
    "            pod_binding_node = node\n",
    "    print(f\"the node with lowest bandwidth is {pod_binding_node} with bandwidth {b}\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigException",
     "evalue": "Service host/port is not set.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/ms_scheduling/node_operation/traffic_aware.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bk8s_master/home/ubuntu/ms_scheduling/node_operation/traffic_aware.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=115'>116</a>\u001b[0m     watch_pod_events()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bk8s_master/home/ubuntu/ms_scheduling/node_operation/traffic_aware.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=118'>119</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bk8s_master/home/ubuntu/ms_scheduling/node_operation/traffic_aware.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=119'>120</a>\u001b[0m     config\u001b[39m.\u001b[39;49mload_incluster_config()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bk8s_master/home/ubuntu/ms_scheduling/node_operation/traffic_aware.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=120'>121</a>\u001b[0m     main()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kubernetes/config/incluster_config.py:121\u001b[0m, in \u001b[0;36mload_incluster_config\u001b[0;34m(client_configuration, try_refresh_token)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_incluster_config\u001b[39m(client_configuration\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, try_refresh_token\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    113\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m    Use the service account kubernetes gives to pods to connect to kubernetes\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39m    cluster. It's intended for clients that expect to be running inside a pod\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m    running on kubernetes. It will raise an exception if called from a process\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m    not running in a kubernetes environment.\"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     InClusterConfigLoader(\n\u001b[1;32m    119\u001b[0m         token_filename\u001b[39m=\u001b[39;49mSERVICE_TOKEN_FILENAME,\n\u001b[1;32m    120\u001b[0m         cert_filename\u001b[39m=\u001b[39;49mSERVICE_CERT_FILENAME,\n\u001b[0;32m--> 121\u001b[0m         try_refresh_token\u001b[39m=\u001b[39;49mtry_refresh_token)\u001b[39m.\u001b[39;49mload_and_set(client_configuration)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kubernetes/config/incluster_config.py:54\u001b[0m, in \u001b[0;36mInClusterConfigLoader.load_and_set\u001b[0;34m(self, client_configuration)\u001b[0m\n\u001b[1;32m     52\u001b[0m     client_configuration \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(Configuration)\n\u001b[1;32m     53\u001b[0m     try_set_default \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_config()\n\u001b[1;32m     55\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_config(client_configuration)\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m try_set_default:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kubernetes/config/incluster_config.py:62\u001b[0m, in \u001b[0;36mInClusterConfigLoader._load_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_config\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m (SERVICE_HOST_ENV_NAME \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_environ\n\u001b[1;32m     61\u001b[0m             \u001b[39mor\u001b[39;00m SERVICE_PORT_ENV_NAME \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_environ):\n\u001b[0;32m---> 62\u001b[0m         \u001b[39mraise\u001b[39;00m ConfigException(\u001b[39m\"\u001b[39m\u001b[39mService host/port is not set.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_environ[SERVICE_HOST_ENV_NAME]\n\u001b[1;32m     65\u001b[0m             \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_environ[SERVICE_PORT_ENV_NAME]):\n\u001b[1;32m     66\u001b[0m         \u001b[39mraise\u001b[39;00m ConfigException(\u001b[39m\"\u001b[39m\u001b[39mService host/port is set but empty.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mConfigException\u001b[0m: Service host/port is not set."
     ]
    }
   ],
   "source": [
    "from os import getenv\n",
    "from json import loads as json_loads\n",
    "import random\n",
    "\n",
    "from kubernetes import config, watch\n",
    "from kubernetes.client import ApiClient, CoreV1Api, V1ObjectReference, V1ObjectMeta, V1Binding, Configuration\n",
    "from kubernetes.client.rest import ApiException, RESTClientObject\n",
    "\n",
    "from logging import basicConfig, getLogger, INFO\n",
    "\n",
    "formatter = \" %(asctime)s | %(levelname)-6s | %(process)d | %(threadName)-12s |\" \\\n",
    "            \" %(thread)-15d | %(name)-30s | %(filename)s:%(lineno)d | %(message)s |\"\n",
    "basicConfig(level=INFO, format=formatter)\n",
    "logger = getLogger(\"meetup-scheduler\")\n",
    "\n",
    "V1_CLIENT = None  # type: CoreV1Api\n",
    "SCHEDULE_STRATEGY = \"schedulingStrategy=meetup\"\n",
    "_NOSCHEDULE_TAINT = \"NoSchedule\"\n",
    "\n",
    "\n",
    "def _get_ready_nodes(v1_client, filtered=True):\n",
    "    ready_nodes = []\n",
    "    try:\n",
    "        for n in v1_client.list_node().items:\n",
    "            if n.metadata.labels.get(\"noCustomScheduler\") == \"yes\":\n",
    "                logger.info(f\"Skipping Node {n.metadata.name} since it has noCustomScheduler label\")\n",
    "                continue\n",
    "            if filtered:\n",
    "                if not n.spec.unschedulable:\n",
    "                    no_schedule_taint = False\n",
    "                    if n.spec.taints:\n",
    "                        for taint in n.spec.taints:\n",
    "                            if _NOSCHEDULE_TAINT == taint.to_dict().get(\"effect\", None):\n",
    "                                no_schedule_taint = True\n",
    "                                break\n",
    "                    if not no_schedule_taint:\n",
    "                        for status in n.status.conditions:\n",
    "                            if status.status == \"True\" and status.type == \"Ready\" and n.metadata.name:\n",
    "                                ready_nodes.append(n.metadata.name)\n",
    "                    else:\n",
    "                        logger.error(\"NoSchedule taint effect on node %s\", n.metadata.name)\n",
    "                else:\n",
    "                    logger.error(\"Scheduling disabled on %s \", n.metadata.name)\n",
    "            else:\n",
    "                if n.metadata.name:\n",
    "                    ready_nodes.append(n.metadata.name)\n",
    "        logger.info(\"Nodes : %s, Filtered: %s\", ready_nodes, filtered)\n",
    "    except ApiException as e:\n",
    "        logger.error(json_loads(e.body)[\"message\"])\n",
    "        ready_nodes = []\n",
    "    return ready_nodes\n",
    "\n",
    "# later add the funtcion for choosing the node from schedulable nodes\n",
    "\n",
    "\n",
    "def _get_schedulable_node(v1_client):\n",
    "    node_list = _get_ready_nodes(v1_client)\n",
    "    if not node_list:\n",
    "        return None\n",
    "    available_nodes = list(set(node_list))\n",
    "    return random.choice(available_nodes) # later add the logic for choosing the node from the list of available nodes\n",
    "\n",
    "\n",
    "def schedule_pod(v1_client, name, node, namespace=\"default\"):\n",
    "    target = V1ObjectReference()\n",
    "    target.kind = \"Node\"\n",
    "    target.apiVersion = \"v1\"\n",
    "    target.name = node\n",
    "    meta = V1ObjectMeta()\n",
    "    meta.name = name\n",
    "    body = V1Binding(api_version=None, kind=None, metadata=meta, target=target)\n",
    "    logger.info(\"Binding Pod: %s  to  Node: %s\", name, node)\n",
    "    return v1_client.create_namespaced_pod_binding(name, namespace, body)\n",
    "\n",
    "def watch_pod_events():\n",
    "    V1_CLIENT = CoreV1Api()\n",
    "    while True:\n",
    "        try:\n",
    "            logger.info(\"Checking for pod events....\")\n",
    "            try:\n",
    "                watcher = watch.Watch()\n",
    "                for event in watcher.stream(V1_CLIENT.list_pod_for_all_namespaces, label_selector=SCHEDULE_STRATEGY, timeout_seconds=20):\n",
    "                    logger.info(f\"Event: {event['type']} {event['object'].kind}, {event['object'].metadata.namespace}, {event['object'].metadata.name}, {event['object'].status.phase}\")\n",
    "                    if event[\"object\"].status.phase == \"Pending\":\n",
    "                        try:\n",
    "                            logger.info(f'{event[\"object\"].metadata.name} needs scheduling...')\n",
    "                            pod_namespace = event[\"object\"].metadata.namespace\n",
    "                            pod_name = event[\"object\"].metadata.name\n",
    "                            service_name = event[\"object\"].metadata.labels[\"serviceName\"]\n",
    "                            logger.info(\"Processing for Pod: %s/%s\", pod_namespace, pod_name)\n",
    "                            node_name = _get_schedulable_node(V1_CLIENT)\n",
    "                            if node_name:\n",
    "                                logger.info(\"Namespace %s, PodName %s , Node Name: %s  Service Name: %s\",\n",
    "                                            pod_namespace, pod_name, node_name, service_name)\n",
    "                                res = schedule_pod(V1_CLIENT, pod_name, node_name, pod_namespace)\n",
    "                                logger.info(\"Response %s \", res)\n",
    "                            else:\n",
    "                                logger.error(f\"Found no valid node to schedule {pod_name} in {pod_namespace}\")\n",
    "                        except ApiException as e:\n",
    "                            logger.error(json_loads(e.body)[\"message\"])\n",
    "                        except ValueError as e:\n",
    "                            logger.error(\"Value Error %s\", e)\n",
    "                        except:\n",
    "                            logger.exception(\"Ignoring Exception\")\n",
    "                logger.info(\"Resetting k8s watcher...\")\n",
    "            except:\n",
    "                logger.exception(\"Ignoring Exception\")\n",
    "            finally:\n",
    "                del watcher\n",
    "        except:\n",
    "            logger.exception(\"Ignoring Exception & listening for pod events\")\n",
    "\n",
    "def main():\n",
    "    logger.info(\"Initializing the meetup scheduler...\")\n",
    "    logger.info(\"Watching for pod events...\")\n",
    "    watch_pod_events()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config.load_incluster_config()\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
